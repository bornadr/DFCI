{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4f5a5c-866b-4285-a3c5-9b7c391013d0",
   "metadata": {},
   "source": [
    "## CLOUD COMPUTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc94ab5-d5cf-463f-a50a-d3473d5e5562",
   "metadata": {},
   "source": [
    "Q1) I think it'd be ideal to use something like AWS S3 and store one copy of each file. This way the copy remains in one place instead of having a copy for each user. Then for the metadata and access control service we can use a lightweight microservice and a relational database like posgresql. The tables are files (id, bucket, key, size…), users, file_acl (user_id, file_id, perms) and a REST API to check the file level permissions of users. For proof of identity we can use something like AWS Cognito where users obtain a JWT used for all subsequent API calls. Then we call the cloud SDK to create a pre-signed URL which expires in 10-15 minutes and return the URL to the client, the pipelines can download via https. Finally for auditing we log every API request and URL issued which then we can monitor via cloudwatch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b51e4-b39a-42db-b20a-2a048913ff22",
   "metadata": {},
   "source": [
    "Q2) My take is that containerizing bioinformatics workflows with Docker gives us reproducibility and environment isolation while Kubernetes has potential for scaling, resource quotas, and cloud‑native integration which makes everything more smooth and automatic. In this case we get microservice‑style pipelines, automatic retries, and memory controls, all via a simple YAML. The trade‑offs, though, are a bit of performance and network overhead from the container runtime and on top that the operational complexity of standing up and maintaining a control plane. In practice, Docker + Kubernetes is better for loosely coupled, stateless analyses and QC services in the cloud, but for tightly coupled, a traditional HPC scheduler combined with a lightweight runtime is most likely the better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e7e46e-c414-4d8a-bf7b-e32b569650c6",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318f9a4-2f71-4d12-99b1-2720f3a1e8c3",
   "metadata": {},
   "source": [
    "In SQL we should either wrap every non‑aggregated column in an aggregate, or Group by it before using HAVING so we just need to add \"GROUP BY UserId\" before \"HAVING COUNT(OrderId) >= 1;\" this way we get one row per userId with invoice count >=1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3150c-439d-44dd-aaf0-618a4f0cfee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
